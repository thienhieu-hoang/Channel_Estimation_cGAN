{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat\n",
    "import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Constants\n",
    "path = \"../DeepMIMOv2/Gan_Data/freq_symb_8ant_612sub/Gan_0_dBOutdoor1_60_8ant_612subcs.mat\"\n",
    "\n",
    "BATCH_SIZE = 64  # Batch size\n",
    "\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File(path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1647, 612, 14, 2, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = file['input_da']\n",
    "input_data.shape\n",
    "output_data = file['output_da']\n",
    "output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_train(path, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Load, jitter, and normalize training images.\n",
    "    \"\"\"\n",
    "    with h5py.File(path, 'r') as file:\n",
    "        Hreal = np.array(file['output_da']) # np.transpose(np.array(file['output_da']),[2,4,3,0,1])       # Nsamples x subcs x symb x 2 x ant\n",
    "        input_data = np.array(file['input_da']) # np.transpose(np.array(file['input_da']),[2,4,3,0,1])\n",
    "\n",
    "    batch_im = random.sample(range(Hreal.shape[0]), Hreal.shape[0])\n",
    "    Hreal, input_data = Hreal[batch_im], input_data[batch_im] \n",
    "    \n",
    "    n_batches = int(Hreal.shape[0] / batch_size)\n",
    " \n",
    "    for i in range(n_batches - 1):\n",
    "        yield Hreal[i*batch_size:(i+1)*batch_size], input_data[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "\n",
    "def load_image_test(path, batch_size=1):\n",
    "    \"\"\"\n",
    "    Load and normalize test images.\n",
    "    \"\"\"\n",
    "    with h5py.File(path, 'r') as file:\n",
    "        Hreal = np.array(file['output_da']) # np.transpose(np.array(file['output_da']),[2,4,3,0,1])   # Nsamples x subcs x symb x 2 x ant\n",
    "        input_data = np.array(file['input_da']) # np.transpose(np.array(file['input_da']),[2,4,3,0,1])\n",
    "\n",
    "    n_batches = int(Hreal.shape[0] / batch_size)\n",
    "\n",
    "    for i in range(n_batches - 1):\n",
    "        yield Hreal[i*batch_size:(i+1)*batch_size], input_data[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "\n",
    "def load_image_test_y(path):\n",
    "    \"\"\"\n",
    "    Load test images.\n",
    "    \"\"\"\n",
    "    with h5py.File(path, 'r') as file:\n",
    "        Hreal = np.array(file['output_da_test']) # np.transpose(np.array(file['output_da_test']),[2,4,3,0,1])   # Nsamples x subcs x symb x 2 x ant\n",
    "        input_data = np.array(file['input_da_test']) # np.transpose(np.array(file['input_da_test']),[2,4,3,0,1])\n",
    "\n",
    "    return Hreal, input_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShrinkLayer(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size, strides_s=2, apply_batchnorm=True, add=False, padding_s='same'):\n",
    "        super(ShrinkLayer, self).__init__()\n",
    "        initializer = tf.random_normal_initializer(mean=0., stddev=0.02)\n",
    "        conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides_s,\n",
    "                             padding=padding_s, kernel_initializer=initializer, use_bias=False)\n",
    "        ac = tf.keras.layers.LeakyReLU()\n",
    "\n",
    "        components = [conv]\n",
    "        if apply_batchnorm:\n",
    "            components.append(tf.keras.layers.BatchNormalization())\n",
    "            components.append(ac)\n",
    "        \n",
    "        self.encoder_layer = tf.keras.Sequential(components)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.encoder_layer(x)\n",
    "\n",
    "\n",
    "class EnlargeLayer(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size, strides_s=2, apply_dropout=False, add=False):\n",
    "        super(EnlargeLayer, self).__init__()\n",
    "        initializer = tf.random_normal_initializer(mean=0., stddev=0.02)\n",
    "        dconv = tf.keras.layers.Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides_s,\n",
    "                                       padding='same', kernel_initializer=initializer, use_bias=False)\n",
    "        bn = tf.keras.layers.BatchNormalization()\n",
    "        ac = tf.keras.layers.ReLU()\n",
    "\n",
    "        components = [dconv, bn]\n",
    "        if apply_dropout:\n",
    "            components.append(tf.keras.layers.Dropout(rate=0.5))\n",
    "        components.append(ac)\n",
    "        \n",
    "        self.decoder_layer = tf.keras.Sequential(components)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.decoder_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Resize Input\n",
    "        # self.p_layers = [\n",
    "        #     DecoderLayer(filters=2, kernel_size=4, strides_s=2, add=True),\n",
    "        #     DecoderLayer(filters=2, kernel_size=4, strides_s=2, add=True),\n",
    "        #     EncoderLayer(filters=2, kernel_size=(6,1), strides_s=(4,1), add=True)\n",
    "        # ]\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_layers = [\n",
    "            ShrinkLayer(filters=64*1, kernel_size=4, apply_batchnorm=False),\n",
    "            ShrinkLayer(filters=64*2, kernel_size=4),\n",
    "            ShrinkLayer(filters=64*4, kernel_size=4),\n",
    "            ShrinkLayer(filters=64*8, kernel_size=4),\n",
    "            ShrinkLayer(filters=64*8, kernel_size=4)\n",
    "        ]\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_layers = [\n",
    "            EnlargeLayer(filters=64*8, kernel_size=4, apply_dropout=True),\n",
    "            EnlargeLayer(filters=64*8, kernel_size=4, apply_dropout=True),\n",
    "            EnlargeLayer(filters=64*8, kernel_size=4, apply_dropout=True),\n",
    "            EnlargeLayer(filters=64*4, kernel_size=4)\n",
    "        ]\n",
    "\n",
    "        initializer = tf.random_normal_initializer(mean=0., stddev=0.02)\n",
    "        self.last = tf.keras.layers.Conv2DTranspose(filters=2, kernel_size=4, strides=2, padding='same',\n",
    "                                           kernel_initializer=initializer, activation='tanh')\n",
    "\n",
    "    def call(self, x):\n",
    "        # Pass the encoder and record xs\n",
    "        # for p_layer in self.p_layers:\n",
    "        #     x = p_layer(x)\n",
    "\n",
    "        encoder_xs = []\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            x = encoder_layer(x)\n",
    "            encoder_xs.append(x)\n",
    "\n",
    "        encoder_xs = encoder_xs[:-1][::-1]  # reverse\n",
    "\n",
    "        # Pass the decoder and apply skip connection\n",
    "        for i, decoder_layer in enumerate(self.decoder_layers):\n",
    "            x = decoder_layer(x)\n",
    "            x = tf.concat([x, encoder_xs[i]], axis=-1)  # skip connect\n",
    "\n",
    "        return self.last(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "        self.encoder_layer_1 = ShrinkLayer(filters=64, kernel_size=4, apply_batchnorm=False)\n",
    "        self.encoder_layer_2 = ShrinkLayer(filters=128, kernel_size=4)\n",
    "        self.encoder_layer_3 = ShrinkLayer(filters=128, kernel_size=4)\n",
    "\n",
    "        self.zero_pad1 = tf.keras.layers.ZeroPadding2D()\n",
    "        self.conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.ac = tf.keras.layers.LeakyReLU()\n",
    "\n",
    "        self.zero_pad2 = tf.keras.layers.ZeroPadding2D()\n",
    "        self.last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, y):\n",
    "        x = y\n",
    "        x = self.encoder_layer_1(x)\n",
    "        x = self.encoder_layer_2(x)\n",
    "        x = self.encoder_layer_3(x)\n",
    "\n",
    "        x = self.zero_pad1(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.ac(x)\n",
    "\n",
    "        x = self.zero_pad2(x)\n",
    "        x = self.last(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.ones_like(disc_real_output), logits=disc_real_output)\n",
    "    generated_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.zeros_like(disc_generated_output), logits=disc_generated_output)\n",
    "    total_disc_loss = tf.reduce_mean(real_loss) + tf.reduce_mean(generated_loss)\n",
    "    return total_disc_loss\n",
    "\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target, l2_weight=100):\n",
    "    gen_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.ones_like(disc_generated_output), logits=disc_generated_output)\n",
    "    l2_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    total_gen_loss = tf.reduce_mean(gen_loss) + l2_weight * l2_loss\n",
    "    return total_gen_loss\n",
    "\n",
    "\n",
    "def generated_image(generator, test_input, target, t=0):\n",
    "        # test_input == Y[:,:,:,:,ant]      == Nsamples x subcs x symb x 2\n",
    "        # target     == H_real[:,:,:,:,ant] == Nsamples x subcs x symb x 2\n",
    "    prediction = generator(test_input)  # H_fake of antenna 'ant' == Nsamples x subcs x symb x 2  \n",
    "    display_list = [np.squeeze(test_input[:, :, :, 0]), np.squeeze(target[:, :, :, 0]), np.squeeze(prediction[:, :, :, 0])]\n",
    "        # real part\n",
    "    title = ['Input Y', 'Target H', 'Prediction H']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.savefig(os.path.join(\"generated_img\", \"img_\"+str(t)+\".png\"))\n",
    "\n",
    "\n",
    "def train_step(input_image, target):\n",
    "        # input_image == Y[:,:,:,:,ant]       == Nsamples x subcs x symb x 2\n",
    "        # target      == H_real[:,:,:,:,ant]  == Nsamples x subcs x symb x 2\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image)\n",
    "        disc_real_output = discriminator(target)\n",
    "        disc_generated_output = discriminator(gen_output)\n",
    "\n",
    "        gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradient = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    discriminator_gradient = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradient, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradient, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.RMSprop(2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    nm = []\n",
    "    ep = []\n",
    "    ant = 0\n",
    "    gen_loss_track  = []\n",
    "    disc_loss_track = []\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"-----\\nEPOCH:\", epoch)\n",
    "        \n",
    "        for bi, (target, input_image) in enumerate(load_image_train(path)):\n",
    "            # input_image == Y_input == Nsamples x subcs x symb x 2 x ant\n",
    "            # target      == H_Real  == Nsamples x subcs x symb x 2 x ant\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "            gen_loss, disc_loss = train_step(input_image[:,:,:,:,ant], target[:,:,:,:,ant])\n",
    "            gen_loss_track.append(gen_loss)\n",
    "            disc_loss_track.append(disc_loss)\n",
    "\n",
    "        for bii, (target, input) in enumerate(load_image_test(path)):\n",
    "            # input   == Y_input == Nsamples x subcs x symb x 2 x ant\n",
    "            # target  == H_Real  == Nsamples x subcs x symb x 2 x ant\n",
    "            if bii == 100:\n",
    "                generated_image(generator, input[:,:,:,:,ant], target[:,:,:,:,ant], t=epoch+1)\n",
    "\n",
    "        realim, inpuim = load_image_test_y(path)\n",
    "            # inpuim == Y_input (test) == Nsamples x subcs x symb x 2 x ant\n",
    "            # realim == H_Real  (test) == Nsamples x subcs x symb x 2 x ant\n",
    "        prediction = generator(inpuim[:,:,:,:,ant])\n",
    "\n",
    "        nm.append(fuzz.nmse(np.squeeze(realim), np.squeeze(prediction)))\n",
    "\n",
    "        if epoch == epochs-1:\n",
    "            nmse_epoch = TemporaryFile()\n",
    "            np.save(nmse_epoch, nm)\n",
    "\n",
    "    return nm, ep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "EPOCH: 0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"generator_2\" \"                 f\"(type Generator).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} ConcatOp : Dimension 1 in both shapes must be equal: shape[0] = [64,40,2,512] vs. shape[1] = [64,39,1,512] [Op:ConcatV2] name: concat\n\nCall arguments received by layer \"generator_2\" \"                 f\"(type Generator):\n  • x=tf.Tensor(shape=(64, 612, 14, 2), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nm, ep \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bi, (target, input_image) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(load_image_train(path)):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# input_image == Y_input == Nsamples x subcs x symb x 2 x ant\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# target      == H_Real  == Nsamples x subcs x symb x 2 x ant\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     elapsed_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m---> 16\u001b[0m     gen_loss, disc_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     gen_loss_track\u001b[38;5;241m.\u001b[39mappend(gen_loss)\n\u001b[0;32m     18\u001b[0m     disc_loss_track\u001b[38;5;241m.\u001b[39mappend(disc_loss)\n",
      "Cell \u001b[1;32mIn[40], line 38\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(input_image, target)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(input_image, target):\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;66;03m# input_image == Y[:,:,:,:,ant]       == Nsamples x subcs x symb x 2\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;66;03m# target      == H_real[:,:,:,:,ant]  == Nsamples x subcs x symb x 2\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m gen_tape, tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m disc_tape:\n\u001b[1;32m---> 38\u001b[0m         gen_output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m         disc_real_output \u001b[38;5;241m=\u001b[39m discriminator(target)\n\u001b[0;32m     40\u001b[0m         disc_generated_output \u001b[38;5;241m=\u001b[39m discriminator(gen_output)\n",
      "File \u001b[1;32mc:\\Users\\AT30890\\AppData\\Local\\anaconda3\\envs\\TF_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[38], line 48\u001b[0m, in \u001b[0;36mGenerator.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_layers):\n\u001b[0;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m decoder_layer(x)\n\u001b[1;32m---> 48\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_xs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# skip connect\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast(x)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"generator_2\" \"                 f\"(type Generator).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} ConcatOp : Dimension 1 in both shapes must be equal: shape[0] = [64,40,2,512] vs. shape[1] = [64,39,1,512] [Op:ConcatV2] name: concat\n\nCall arguments received by layer \"generator_2\" \"                 f\"(type Generator):\n  • x=tf.Tensor(shape=(64, 612, 14, 2), dtype=float32)"
     ]
    }
   ],
   "source": [
    "nm, ep = train(epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save_weights('saved_model/test/generator_weights.h5')\n",
    "generator.save('saved_model/test/generator_arch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.save_weights('saved_model/test/discriminator_weights.h5')\n",
    "discriminator.save('saved_model/test/discriminator_arch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(NUM_EPOCHS), nm, '^-r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('NMSE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
